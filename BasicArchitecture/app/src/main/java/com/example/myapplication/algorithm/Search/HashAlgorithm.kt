package com.example.myapplication.algorithm.Search

class HashAlgorithm {
//    <1>安全加密
//    MD5  SHA
//
//    <2>唯一标识
//
//    <3>数据校验
//
//    <4>散列函数
//
//    <5>负载均衡
//    对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 这样，我们就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。
//
//    <6>数据分片
//    (1)如何统计”搜索关键字”出现的次数
//    假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？
//    难点有两个：
//    1.日志很大，没办法放在一台机器内存中
//    2.如果一台机器来处理这么巨大的数据，处理时间会很长。
//
//    用n台机器进行处理，我们从搜索记录的日志文件中，依次读出每个搜索的关键字，并且通过哈希函数计算哈希值，然后再跟n取模，最终得到的值，就是应该被分配的机器编号(相同的关键字会分到同一个机器)。
//
//    (2)判断图片是否在图库中
//    假设现在我们的图库中有 1 亿张图片，很显然，在单台机器上构建散列表是行不通的。因为单台机器的内存有限，而 1 亿张图片构建散列表显然远远超过了单台机器的内存上限。
//
//    我们同样可以对数据进行分片，然后采用多机处理。我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。
//
//    <7>分布式存储
//    之前说的我们根据服务器的多少来取模，来做分布存储，但是如果要增加机器怎么办？
//    如果按照以前的方法增加了一台机器，所有的数据需重新算,
//
//    所以我们需要一种方法，使得新加入一个机器后，并不需要做大量的数据搬移，这时候，一致性哈希算法就要登场了。
//    http://www.zsythink.net/archives/1182
//
//
//    用了一个hash环，然后用虚拟节点解决hash环偏斜的问题
//
//    假设有K个机器，数据的哈希值的范围[0,MAX].   (有点问题？？？)
//    我们将整个范围划分成m个小区间(m远大于k),每个机器负责m/k小区间。
//    当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。
//    这样既不用全部重新哈希，搬移数据，也保持了各个机器上数据数量的均衡。
//
//    一致性哈希算法的基本思想就是这么简单。除此之外，它还会借助一个虚拟的环和虚拟结点，更加优美地实现出来。
//
//
//    除了我们上面讲到的分布式缓存，实际上，一致性哈希算法的应用非常广泛，在很多分布式存储系统中，都可以见到一致性哈希算法的影子。
}